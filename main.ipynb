{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import theano\n",
    "from theano import tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First two rows of data\n",
      "\n",
      "\n",
      "[[  1.  77.  61.  62.  68.  62.  58.  72.  68.  77.  71.  76.  77.  72.\n",
      "   75.  62.  57.  77.  74.  61.  58.  72.  76.  69.  68.  56.  53.  57.\n",
      "   54.  69.  70.  73.  79.  65.  70.  66.  68.  67.  66.  71.  67.  60.\n",
      "   60.  53.  57.]\n",
      " [  1.  75.  79.  65.  74.  63.  64.  74.  73.  73.  71.  76.  79.  70.\n",
      "   69.  55.  64.  69.  71.  79.  76.  77.  78.  65.  70.  60.  60.  65.\n",
      "   61.  70.  65.  74.  71.  62.  62.  69.  67.  72.  72.  72.  66.  61.\n",
      "   64.  55.  54.]]\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "filename = 'SPECTF.dat'\n",
    "data = np.loadtxt(filename, delimiter=',')\n",
    "X = data[:, 1:]\n",
    "y = np.array([data[:, 0]]).T\n",
    "n, d = X.shape\n",
    "\n",
    "#divide data to train and test for cross validation\n",
    "select = list(range(n))\n",
    "random.shuffle(select)\n",
    "select_train = np.array(select[0:int(9*n / 10)])\n",
    "select_test = np.array(select[int(9*n / 10):n])\n",
    "\n",
    "data_train = data[select_train, :]\n",
    "data_test = data[select_test, :]\n",
    "print('First two rows of data\\n\\n')\n",
    "print(data_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First two labels of data\n",
      "\n",
      "\n",
      "[ 1.  1.]\n",
      "\n",
      "\n",
      "First two feature-rows of data\n",
      "\n",
      "\n",
      "[[ 77.  61.  62.  68.  62.  58.  72.  68.  77.  71.  76.  77.  72.  75.\n",
      "   62.  57.  77.  74.  61.  58.  72.  76.  69.  68.  56.  53.  57.  54.\n",
      "   69.  70.  73.  79.  65.  70.  66.  68.  67.  66.  71.  67.  60.  60.\n",
      "   53.  57.]\n",
      " [ 75.  79.  65.  74.  63.  64.  74.  73.  73.  71.  76.  79.  70.  69.\n",
      "   55.  64.  69.  71.  79.  76.  77.  78.  65.  70.  60.  60.  65.  61.\n",
      "   70.  65.  74.  71.  62.  62.  69.  67.  72.  72.  72.  66.  61.  64.\n",
      "   55.  54.]]\n"
     ]
    }
   ],
   "source": [
    "#divide data to labels and features\n",
    "data_train_Y=data_train[:,0]\n",
    "data_train_X=data_train[:,1:data_train.shape[1]]\n",
    "\n",
    "data_test_Y=data_test[:,0]\n",
    "data_test_X=data_test[:,1:data_test.shape[1]]\n",
    "print(\"First two labels of data\\n\\n\")\n",
    "print(data_train_Y[:2])\n",
    "print(\"\\n\\nFirst two feature-rows of data\\n\\n\")\n",
    "print(data_train_X[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, Y, step_size, max_steps):\n",
    "    def Xnorm(a):  # a is an m*n matrix, return is nD vector where element 'i' is the average of all m elements in 'i'th column\n",
    "        a = np.array(a)\n",
    "        norms = np.zeros(a.shape[1])\n",
    "        if len(a.shape) != 1:\n",
    "            for i in range(a.shape[1]):\n",
    "                norms[i] = np.sum([a[j, i] for j in range(a.shape[0])]) / a.shape[0]\n",
    "        else:\n",
    "            for i in range(a.shape[1]):\n",
    "                norms[i] = a[i]\n",
    "        return norms\n",
    "\n",
    "    for i in range(len(Y)):\n",
    "        if Y[i] == 0:\n",
    "            Y[i] = -1\n",
    "    X = np.array(X)\n",
    "    Xnorms = Xnorm(X)\n",
    "\n",
    "    a = T.vector()\n",
    "    b = T.vector()\n",
    "    c = T.scalar()\n",
    "\n",
    "    loss = np.log(1 + np.exp(-c * (a.dot(b))))\n",
    "\n",
    "    grad = theano.function([a, b, c], T.grad(loss, b))\n",
    "\n",
    "    beta = np.zeros(X.shape[1])\n",
    "    for s in range(max_steps):\n",
    "        r = list(range(X.shape[0] - 1))\n",
    "        random.shuffle(r)\n",
    "        for f in r:\n",
    "            beta[0] = beta[0] - grad(X[f], beta, Y[f])[0] / Xnorms[0]\n",
    "            for i in range(1, X.shape[1]):\n",
    "                beta[i] = beta[i] - (step_size) * grad(X[f], beta, Y[f])[i] / (Xnorms[i] * X.shape[0])\n",
    "\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Logistic Reg. Accuracy = ', 75)\n"
     ]
    }
   ],
   "source": [
    "beta=gradient_descent(data_train_X,data_train_Y, step_size=10, max_steps=20)\n",
    "\n",
    "def accuracy_score(Y_true, Y_predict):\n",
    "    error=0\n",
    "    for i in range(len(Y_predict)):\n",
    "        if Y_true[i] != Y_predict[i]:\n",
    "            error = error + 1\n",
    "    error= error*100/len(Y_predict)\n",
    "    return 100-error\n",
    "\n",
    "Y_log_pred=[]\n",
    "for i in range(data_test_X.shape[0]):\n",
    "    if data_test_X[i].T.dot(beta)>0:\n",
    "        Y_log_pred.append(1)\n",
    "    else:\n",
    "        Y_log_pred.append(0)\n",
    "log_accuracy=accuracy_score(data_test_Y, Y_log_pred)\n",
    "\n",
    "print(\"Logistic Reg. Accuracy = \", log_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
